{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGj6+s1W6HFlumf1iX68HC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelTotaro/github.io/blob/master/Summer_2025_INFX_639_Ch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUcLeoZ5gFdc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 3: Deep Learning Libraries**"
      ],
      "metadata": {
        "id": "qcXQ-Am3gIUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chapter discusses the important libraries and frameworks that one needs to get started in artificial intelligence. We'll cover the basic functions of the three most popular deep learning frameworks: Tensorflow, Pytorch, and Keras, and show you how to get up and running in each of these frameworks as we will be utilizing them in the following chapters. A reminder that these deep learning frameworks are already pre-installed in Google Colab.\n",
        "\n",
        "Finally, the chapter touches upon computing for Artificial Intelligence, and discusses how GPUs and other advanced memory units can improve AI."
      ],
      "metadata": {
        "id": "Drq2WT2Hgaur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_O66UbiVhQ9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TensorFlow Basics**"
      ],
      "metadata": {
        "id": "wb-o4ilNhWvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "uVKymuOZhjp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define two constants\n",
        "x = tf.constant(2)\n",
        "y = tf.constant(2)\n",
        "\n",
        "## Multiply the constants\n",
        "product = tf.multiply(x, y)"
      ],
      "metadata": {
        "id": "iHGqgnTxiOWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two constants\n",
        "x = tf.constant(2)\n",
        "y = tf.constant(2)\n",
        "\n",
        "# Multiply the constants\n",
        "product = tf.multiply(x, y)\n",
        "\n",
        "# In TensorFlow 2.x, operations are executed eagerly,\n",
        "# so we don't need to initialize variables or use sessions\n",
        "print(product.numpy()) # Use .numpy() to get the value of the tensor\n",
        "\n",
        "# No session to close in eager execution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szN1avbaiPwe",
        "outputId": "17039b5d-0a4c-4b92-ed66-6b9941c54115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new graph"
      ],
      "metadata": {
        "id": "MgEXl8DficB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_graph = tf.Graph()\n",
        "\n",
        "with my_graph.as_default():\n",
        "            x = tf.constant(2)\n",
        "            y = tf.constant(2)"
      ],
      "metadata": {
        "id": "8syN95C8iecV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scopes:"
      ],
      "metadata": {
        "id": "-UV8lDpPilug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"my_scope\"):\n",
        "            ## Define two constants\n",
        "            const1 = tf.constant([4])\n",
        "            const2 = tf.constant([5])\n",
        "\n",
        "            ## Multiply the constants\n",
        "            product = tf.multiply(const1, const2)"
      ],
      "metadata": {
        "id": "Y2Ztxvm7io25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Keras Basics**"
      ],
      "metadata": {
        "id": "6NBZH2xsiusF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Keras is designed as a model-level library, it does not contain methods for doing basic operations as PyTorch of base TensorFlow does. Instead, it utilizes TensorFlow as a backend. As such, its basic operations are the same as basic TensorFlow operations:"
      ],
      "metadata": {
        "id": "3eYQ7TiHjJOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "NHUTtXY7jNGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using TensorFlow backend."
      ],
      "metadata": {
        "id": "nYXFExmGjQEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K # Keep this import if other Keras backend functions are used later\n",
        "\n",
        "# Using tf.constant directly\n",
        "x = tf.constant(5)\n",
        "y = tf.constant(6)\n",
        "product = x * y\n",
        "\n",
        "# You can still print the result similar to how you did with TensorFlow basics\n",
        "print(product.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XamnQdO8jSB1",
        "outputId": "3c1b7411-7242-408c-fcce-7a6b517fa3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PyTorch**"
      ],
      "metadata": {
        "id": "30eqbn8sjdVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yLONdcgkjjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.IntTensor([4])\n",
        "y = torch.IntTensor([5])\n",
        "product = x * y"
      ],
      "metadata": {
        "id": "tCKU8MTLkDY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to switch between numpy and pytorch"
      ],
      "metadata": {
        "id": "LVbPrKGZkHDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a numpy array\n",
        "numpy_array = np.random.randn(10,10)\n",
        "\n",
        "##Convert the numpy array to a pytorch tesnor\n",
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "\n",
        "## Convert it back to Numpy\n",
        "numpy_again = pytorch_tensor.numpy()"
      ],
      "metadata": {
        "id": "Q2iPKuU3kNVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch tensors can be manipulated in a way that is similar to numpy"
      ],
      "metadata": {
        "id": "zP1p3YvGkPze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.FloatTensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "## print the third element of the 2nd row of the tensor\n",
        "print(tensor[1][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNgARG12kSm8",
        "outputId": "f0229cea-2e3c-425b-c4f2-2c4517e31063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## replace the second value of the first tensor\n",
        "tensor[0][1] = 1\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utQ-NdB7kZba",
        "outputId": "f500c557-9b03-4198-8f2a-3b18389044de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like TensorFlow, PyTorch runs on the concept of variables, which are values that are intended to change and be updated during training processes"
      ],
      "metadata": {
        "id": "LdQhGkiKkdxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "## Create a tensor\n",
        "tensor_two = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "## Convert it to a variable\n",
        "variable = Variable(tensor_two)"
      ],
      "metadata": {
        "id": "kzQmK1bCkecf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHxQu_a6kmyP",
        "outputId": "29c66c2b-15ea-42e8-ba7a-5ca1965c6269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TensorFlow Logging**"
      ],
      "metadata": {
        "id": "7W_PqJpakpvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "my_list = []\n",
        "## Iterate through the available GPUs\n",
        "# Note: In a real environment, you would check if these devices are available.\n",
        "# For demonstration, we'll assume they are or let TensorFlow handle device placement.\n",
        "# In TensorFlow 2.x, device placement is often handled automatically.\n",
        "# You can list available devices using tf.config.list_physical_devices()\n",
        "available_devices = tf.config.list_physical_devices()\n",
        "print(\"Available devices:\", available_devices)\n",
        "\n",
        "\n",
        "for device in ['/gpu:0', '/gpu:1']:\n",
        "    ## Utilize the TensorFlow device manager\n",
        "    try:\n",
        "        with tf.device(device):\n",
        "            x = tf.constant([1,2,3], shape=[1,3])\n",
        "            # Fix: Add '=' after shape to make it a keyword argument\n",
        "            y = tf.constant([1,2,3], shape=[3,1])\n",
        "            # In TensorFlow 2.x, tf.matmul returns a tensor directly in eager execution\n",
        "            matmul_result = tf.matmul(x, y)\n",
        "            my_list.append(matmul_result)\n",
        "            # Print the result of the matrix multiplication\n",
        "            print(f\"Matrix multiplication on {device}:\")\n",
        "            print(matmul_result.numpy())\n",
        "\n",
        "    except tf.errors.InvalidArgumentError as e:\n",
        "        # Catch errors if a device is not available\n",
        "        print(f\"Device {device} not available or operation failed: {e}\")\n",
        "\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    # Note: tf.add requires shapes to be compatible for element-wise addition.\n",
        "    # Adding a (1,3) tensor and a (3,1) tensor directly will result in a (3,3) tensor due to broadcasting.\n",
        "    # This might not be the intended behavior if element-wise addition was expected.\n",
        "    # If you want element-wise addition, shapes must match.\n",
        "    # Example:\n",
        "    # x_cpu = tf.constant([[1, 2, 3]])\n",
        "    # y_cpu = tf.constant([[1, 2, 3]]) # y_cpu needs to have the same shape\n",
        "    # sum_operation = tf.add(x_cpu, y_cpu)\n",
        "\n",
        "    # Based on the original code structure, it seems you intended to add x and y.\n",
        "    # TensorFlow 2.x broadcasting will handle this, resulting in a (3,3) tensor.\n",
        "    sum_operation = tf.add(x, y)\n",
        "    # Print the result of the addition\n",
        "    print(\"\\nAddition on /cpu:0:\")\n",
        "    print(sum_operation.numpy())\n",
        "\n",
        "\n",
        "# Note: In TensorFlow 2.x eager execution, you don't need a session.\n",
        "# Operations are executed immediately when they are called.\n",
        "# The results are available directly as tensors.\n",
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) # This line is removed\n",
        "# sess.run(sum_operation) # This line is removed\n",
        "\n",
        "# Access the results directly\n",
        "# print(sum_operation.numpy()) # Already printed above\n",
        "# print(my_list[-1].numpy()) # Access the last matrix multiplication result, already printed above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyme9ml3kvFt",
        "outputId": "edeef144-a53a-44eb-dee8-d83a6756d928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Matrix multiplication on /gpu:0:\n",
            "[[14]]\n",
            "Matrix multiplication on /gpu:1:\n",
            "[[14]]\n",
            "\n",
            "Addition on /cpu:0:\n",
            "[[2 3 4]\n",
            " [3 4 5]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    }
  ]
}